{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Using Machine Learning APIs </h1>\n",
    "\n",
    "First, visit <a href=\"http://console.cloud.google.com/apis\">API console</a>, choose \"Credentials\" on the left-hand menu.  Choose \"Create Credentials\" and generate an API key for your application. You should probably restrict it by IP address to prevent abuse, but for now, just  leave that field blank and delete the API key after trying out this demo.\n",
    "\n",
    "Copy-paste your API Key here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "APIKEY=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note: Make sure you generate an API Key and replace the value above. The sample key will not work.</b>\n",
    "\n",
    "From the same API console, choose \"Dashboard\" on the left-hand menu and \"Enable API\".\n",
    "\n",
    "Enable the following APIs for your project (search for them) if they are not already enabled:\n",
    "<ol>\n",
    "<li> Google Translate API </li>\n",
    "<li> Google Cloud Vision API </li>\n",
    "<li> Google Natural Language API </li>\n",
    "<li> Google Cloud Speech API </li>\n",
    "</ol>\n",
    "\n",
    "Finally, because we are calling the APIs from Python (clients in many other languages are available), let's install the Python package (it's not installed by default on Datalab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 Google Inc.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "!pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Invoke OCR </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Invoke Vision API </h2>\n",
    "\n",
    "The Vision API can work off an image in Cloud Storage or embedded directly into a POST message. I'll use Cloud Storage and do OCR on this image:\n",
    "<br>\n",
    "<img src=\"https://storage.googleapis.com/video-ted/images/6.png\" width=\"750\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"This is your ticket.', 'Present this entire page at the event.', 'ticketmaster', 'ISSUED TO DTI Management', 'ISSUED ON Jan 19, 2017', 'SECTION 410', 'ROW N', 'SEAT 2', 'ORDER NO.', 'N-', '$36.00 410', '16555292', 'ANAHEIM DUCKS', 'VS.', 'EDMONTON OILERS', 'WED 01/25/2017 7:00PM', 'HONDA CENTER', 'TERR CONCOURSE', '\"']\n"
     ]
    }
   ],
   "source": [
    "# Running Vision API\n",
    "import base64\n",
    "import json\n",
    "IMAGE=\"gs://video-ted/images/6.png\"\n",
    "vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "                    'source': {\n",
    "                        'gcs_image_uri': IMAGE\n",
    "                    }\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': 'TEXT_DETECTION',\n",
    "                    'maxResults': 3,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "responses = request.execute(num_retries=3)\n",
    "#print (responses)\n",
    "#texts = responses.responses[0].text_annotations\n",
    "parse_this =  json.dumps(responses[\"responses\"][0]['textAnnotations'][0]['description'])\n",
    "x = parse_this.split('\\\\n')\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Invoke Vision API </h2>\n",
    "\n",
    "The Vision API can work off an image in Cloud Storage or embedded directly into a POST message. I'll use Cloud Storage and do OCR on this image:\n",
    "<br>\n",
    "<img src=\"https://storage.googleapis.com/video-ted/images/8.png\" width=\"450\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"CALBEARS.COM', 'CAL ATHLETICE', '(\\\\u7fbd', 'C30', 'Cal Mens Basketball vs Stanfor', 'Sunday, January 29, 2017 5:30 PM', 'Section: 16', 'Row: C', 'Seat: 17', 'Reserved', 'No Printing Required - Bring Phone to Venue Entrance', '\"']\n"
     ]
    }
   ],
   "source": [
    "# Running Vision API\n",
    "import base64\n",
    "import json\n",
    "IMAGE=\"gs://video-ted/images/8.png\"\n",
    "vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "                    'source': {\n",
    "                        'gcs_image_uri': IMAGE\n",
    "                    }\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': 'TEXT_DETECTION',\n",
    "                    'maxResults': 3,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "responses = request.execute(num_retries=3)\n",
    "parse_this =  json.dumps(responses[\"responses\"][0]['textAnnotations'][0]['description'])\n",
    "x = parse_this.split('\\\\n')\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Invoke Vision API </h2>\n",
    "\n",
    "The Vision API can work off an image in Cloud Storage or embedded directly into a POST message. I'll use Cloud Storage and do OCR on this image:\n",
    "<br>\n",
    "<img src=\"https://storage.googleapis.com/video-ted/images/chinese.jpg\" width=\"450\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh 4061458 Y57 1次 八达岭\n",
      "北京北\n",
      "Beijingbei\n",
      "Badaling\n",
      "2009年09月03日11:08开\n",
      "¥ 14.00元\n",
      "限乘当日当次车\n",
      "05车050号\n",
      "动车组二等座\n",
      "折\n",
      "127130330003 A 0614% 0813036968261345138198563533723001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running Vision API\n",
    "import base64\n",
    "import json\n",
    "IMAGE=\"gs://video-ted/images/chinese.jpg\"\n",
    "vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "                    'source': {\n",
    "                        'gcs_image_uri': IMAGE\n",
    "                    }\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': 'TEXT_DETECTION',\n",
    "                    'maxResults': 3,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "responses = request.execute(num_retries=3)\n",
    "foreigntext = responses['responses'][0]['textAnnotations'][0]['description']\n",
    "foreignlang = responses['responses'][0]['textAnnotations'][0]['locale']\n",
    "print foreignlang, foreigntext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4061458 Y57 1次 八达岭\n",
      "北京北\n",
      "Beijingbei\n",
      "Badaling\n",
      "2009年09月03日11:08开\n",
      "¥ 14.00元\n",
      "限乘当日当次车\n",
      "05车050号\n",
      "动车组二等座\n",
      "折\n",
      "127130330003 A 0614% 0813036968261345138198563533723001\n",
      " -> 4061458 Y57 1 Badaling Beijing Beijing North Beijingbei Badaling 2009-09-03 at 11:08 open ¥ 14.00 Yuan Limitation ride the same day the car 05 car 050 EMU second-class seat 127130330003 A 0614% 0813036968261345138198563533723001\n"
     ]
    }
   ],
   "source": [
    "inputs=[foreigntext]\n",
    "outputs = service.translations().list(source=foreignlang, target='en', q=inputs).execute()\n",
    "# print outputs\n",
    "for input, output in zip(inputs, outputs['translations']):\n",
    "  print u\"{0} -> {1}\".format(input, output['translatedText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
